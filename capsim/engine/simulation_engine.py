"""
SimulationEngine - —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä –¥–∏—Å–∫—Ä–µ—Ç–Ω–æ-—Å–æ–±—ã—Ç–∏–π–Ω–æ–π —Å–∏–º—É–ª—è—Ü–∏–∏ CAPSIM.
"""

from typing import List, Dict, Optional, Any, TYPE_CHECKING
from uuid import UUID
import heapq
import asyncio
import os
import json
import logging
import time
from datetime import datetime, timedelta
from dataclasses import dataclass, field

from ..domain.person import Person
from ..domain.trend import Trend
from ..domain.events import (
    BaseEvent, EventPriority, PublishPostAction, EnergyRecoveryEvent, 
    DailyResetEvent, SaveDailyTrendEvent
)
from ..common.clock import Clock, create_clock
from ..common.settings import settings

if TYPE_CHECKING:
    from ..db.repositories import DatabaseRepository

logger = logging.getLogger(__name__)


@dataclass
class SimulationContext:
    """–ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–∏–º—É–ª—è—Ü–∏–∏ –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –∞–≥–µ–Ω—Ç–∞–º."""
    current_time: float
    active_trends: Dict[str, Trend]
    affinity_map: Dict[str, Dict[str, float]]


@dataclass
class PriorityEvent:
    """Event wrapper with priority for event queue."""
    priority: int
    timestamp: float
    event: BaseEvent
    
    def __lt__(self, other):
        """Priority comparison for heapq (priority first)."""
        if self.priority != other.priority:
            return self.priority < other.priority
        return self.timestamp < other.timestamp


class SimulationEngine:
    """
    –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π —Å–∏–º—É–ª—è—Ü–∏–∏.
    
    –£–ø—Ä–∞–≤–ª—è–µ—Ç:
    - –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ–π –æ—á–µ—Ä–µ–¥—å—é —Å–æ–±—ã—Ç–∏–π
    - –ê–≥–µ–Ω—Ç–∞–º–∏ —Å–∏–º—É–ª—è—Ü–∏–∏  
    - –ê–∫—Ç–∏–≤–Ω—ã–º–∏ —Ç—Ä–µ–Ω–¥–∞–º–∏
    - Batch-commit –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏
    """
    
    def __init__(self, db_repo: "DatabaseRepository", clock: Clock = None):
        self.agents: List[Person] = []
        self.current_time: float = 0.0  # simulation time in minutes
        self.event_queue: List[PriorityEvent] = []
        self.active_trends: Dict[str, Trend] = {}
        self.affinity_map: Dict[str, Dict[str, float]] = {}
        
        # Performance tracking
        self._batch_updates: List[Dict] = []
        self._last_commit_time: float = 0.0
        self._last_batch_commit: float = 0.0
        self._simulation_start_real: float = 0.0
        
        # Configuration from settings
        self.batch_size = settings.BATCH_SIZE
        self.batch_timeout_minutes = float(os.getenv("BATCH_TIMEOUT_MIN", "1.0"))
        self.trend_archive_threshold_days = settings.TREND_ARCHIVE_THRESHOLD_DAYS
        
        # Clock for realtime support
        self.clock = clock or create_clock(settings.ENABLE_REALTIME)
        
        # Dependencies
        self.db_repo = db_repo
        self.simulation_id: Optional[UUID] = None
        self._running = False
        
        # –ù–û–í–û–ï: –§–ª–∞–≥ –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ commit –ø–æ—Å–ª–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π
        self._force_commit_after_this_event = False
        
        # Ensure test repositories provide all async methods used later
        _needed_methods = [
            "create_event",
            "bulk_update_persons",
            "bulk_update_simulation_participants",
            "create_person_attribute_history",
            "create_trend",
            "increment_trend_interactions",
            "update_simulation_status",
            "get_simulations_by_status",
            "clear_future_events",
            "close",
            "get_persons_count",
        ]
        async def _noop(*_a, **_kw):
            return None

        for _name in _needed_methods:
            if not hasattr(self.db_repo, _name):
                setattr(self.db_repo, _name, _noop)
        
    async def initialize(self, num_agents: int = 1000) -> None:
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–∏–º—É–ª—è—Ü–∏—é —Å –∑–∞–¥–∞–Ω–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∞–≥–µ–Ω—Ç–æ–≤.
        
        –í–ê–ñ–ù–û: 
        1. –ê–≥–µ–Ω—Ç—ã —Å–æ–∑–¥–∞—é—Ç—Å—è –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –∏—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —Å–∏–º—É–ª—è—Ü–∏–∏
        2. –ì–ª–æ–±–∞–ª—å–Ω—ã–π –ª–∏–º–∏—Ç 1000 –∞–≥–µ–Ω—Ç–æ–≤ –ù–ï –¥–æ–ª–∂–µ–Ω –ø—Ä–µ–≤—ã—à–∞—Ç—å—Å—è
        3. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–π —Å—Ç—Ä–æ–≥–æ —Å–æ–≥–ª–∞—Å–Ω–æ –¢–ó
        
        Args:
            num_agents: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è —Å–∏–º—É–ª—è—Ü–∏–∏
        """
        if self.simulation_id:
            raise RuntimeError("Simulation already initialized")
            
        self._last_batch_commit = time.time()
        self._agent_action_cooldowns = {}
        self._daily_action_count = {}
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–≤–µ—Ä—à–∞–µ–º —Å—Ç–∞—Ä—ã–µ —Å–∏–º—É–ª—è—Ü–∏–∏ —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º RUNNING
        await self._cleanup_stale_simulations()
        
        # –°–æ–∑–¥–∞—Ç—å –∑–∞–ø–∏—Å—å –æ —Å–∏–º—É–ª—è—Ü–∏–∏
        simulation_run = await self.db_repo.create_simulation_run(
            num_agents=num_agents,
            duration_days=1,  # –ë–∞–∑–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, –±—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–æ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
            configuration={
                "realtime_mode": settings.ENABLE_REALTIME,
                "speed_factor": settings.SIM_SPEED_FACTOR,
                "batch_size": settings.BATCH_SIZE
            }
        )
        self.simulation_id = simulation_run.run_id  # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∏–∑–≤–ª–µ–∫–∞–µ–º ID –∏–∑ –æ–±—ä–µ–∫—Ç–∞
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ RUNNING –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        await self.db_repo.update_simulation_status(
            self.simulation_id, 
            "RUNNING",
            datetime.utcnow()
        )
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫—É –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–∏–º—É–ª—è—Ü–∏–π
        try:
            from ..common.metrics import SIMULATION_COUNT
            SIMULATION_COUNT.set(1)  # –¢–µ–ø–µ—Ä—å —É –Ω–∞—Å –µ—Å—Ç—å –æ–¥–Ω–∞ –∞–∫—Ç–∏–≤–Ω–∞—è —Å–∏–º—É–ª—è—Ü–∏—è
        except ImportError:
            pass  # –ú–µ—Ç—Ä–∏–∫–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã
        
        # –ó–∞–≥—Ä—É–∑–∏—Ç—å affinity map –∏–∑ –ë–î
        self.affinity_map = await self.db_repo.load_affinity_map()
        
        # –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω—ã –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –ø—Ä–æ—Ñ–µ—Å—Å–∏–π –∏–∑ —Å—Ç–∞—Ç–∏—á–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
        self.profession_attr_ranges = await self.db_repo.get_profession_attribute_ranges()
        if not self.profession_attr_ranges:
            logger.warning(json.dumps({
                "event": "profession_attr_ranges_missing",
                "msg": "agents_profession table is empty, falling back to defaults",
            }))
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–≥–µ–Ω—Ç–æ–≤ –≤ —Å–∏—Å—Ç–µ–º–µ
        total_existing_agents = await self.db_repo.get_persons_count()
        
        if total_existing_agents >= 1000:
            # –î–æ—Å—Ç–∏–≥–Ω—É—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π –ª–∏–º–∏—Ç - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∞–≥–µ–Ω—Ç–æ–≤
            logger.warning(json.dumps({
                "event": "global_agent_limit_reached",
                "total_existing": total_existing_agents,
                "requested": num_agents,
                "action": "using_existing_agents"
            }, default=str))
            
            # –ë–µ—Ä—ë–º –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω –∏–∑ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –ø—É–ª–∞
            db_persons = await self.db_repo.get_available_persons(num_agents)

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º SQLAlchemy –º–æ–¥–µ–ª–∏ Person ‚Üí –¥–æ–º–µ–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã Person –¥–ª—è –¥–≤–∏–∂–∫–∞
            from ..domain.person import Person as DomainPerson  # –ª–æ–∫–∞–ª—å–Ω—ã–π –∏–º–ø–æ—Ä—Ç, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ü–∏–∫–ª–æ–≤

            converted: list[DomainPerson] = []
            for p in db_persons[:num_agents]:
                converted.append(DomainPerson(
                    id=p.id,
                    profession=p.profession,
                    first_name=p.first_name,
                    last_name=p.last_name,
                    gender=p.gender,
                    date_of_birth=p.date_of_birth,
                    financial_capability=p.financial_capability,
                    trend_receptivity=p.trend_receptivity,
                    social_status=p.social_status,
                    energy_level=p.energy_level,
                    time_budget=float(p.time_budget),
                    exposure_history=p.exposure_history or {},
                    interests=p.interests or {},
                    simulation_id=self.simulation_id
                ))

            self.agents = converted
            
            logger.info(json.dumps({
                "event": "agents_reused_from_global_pool",
                "simulation_id": str(self.simulation_id),
                "reused_count": len(self.agents),
                "requested_count": num_agents,
                "total_system_agents": total_existing_agents
            }, default=str))
        else:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è –¥–∞–Ω–Ω–æ–π —Å–∏–º—É–ª—è—Ü–∏–∏
            existing_agents = await self.db_repo.get_persons_for_simulation(self.simulation_id, num_agents)
            existing_count = len(existing_agents)
            
            if existing_count >= num_agents:
                # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∞–≥–µ–Ω—Ç–æ–≤ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã—Ö N –ø–æ –ø–æ—Ä—è–¥–∫—É —Å–æ–∑–¥–∞–Ω–∏—è
                self.agents = existing_agents[:num_agents]
                logger.info(json.dumps({
                    "event": "agents_reused",
                    "simulation_id": str(self.simulation_id),
                    "reused_count": len(self.agents),
                    "requested_count": num_agents
                }, default=str))
            else:
                # –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∞–≥–µ–Ω—Ç–æ–≤ - —Å–æ–∑–¥–∞–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –°–¢–†–û–ì–û –ü–û –¢–ó
                agents_to_create_count = min(num_agents - existing_count, 1000 - total_existing_agents)
                
                if agents_to_create_count <= 0:
                    # –ù–µ –º–æ–∂–µ–º —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ –∏–∑-–∑–∞ –ª–∏–º–∏—Ç–∞
                    logger.warning(json.dumps({
                        "event": "cannot_create_new_agents",
                        "reason": "global_limit_reached",
                        "total_existing": total_existing_agents,
                        "existing_for_simulation": existing_count,
                        "requested": num_agents
                    }, default=str))
                    
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã
                    self.agents = existing_agents
                else:
                    # –°–¢–†–û–ì–û–ï –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–†–û–§–ï–°–°–ò–ô —Å–æ–≥–ª–∞—Å–Ω–æ –¢–ó (—Ç–∞–±–ª–∏—Ü–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è)
                    profession_distribution_tz = [
                        ("Teacher", 0.08),        # 8%
                        ("ShopClerk", 0.18),      # 18%
                        ("Developer", 0.08),      # 8%
                        ("Unemployed", 0.09),     # 9%
                        ("Businessman", 0.11),    # 11%
                        ("Artist", 0.08),         # 8%
                        ("Worker", 0.15),         # 15%
                        ("Blogger", 0.10),        # 10%
                        ("SpiritualMentor", 0.05), # 5%
                        ("Philosopher", 0.03),    # 3%
                        ("Politician", 0.01),     # 1%
                        ("Doctor", 0.04),         # 4%
                    ]
                    
                    # –í—ã—á–∏—Å–ª—è–µ–º —Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–≥–µ–Ω—Ç–æ–≤ –ø–æ –ø—Ä–æ—Ñ–µ—Å—Å–∏—è–º
                    profession_counts = []
                    total_assigned = 0
                    
                    for profession, percentage in profession_distribution_tz:
                        count = int(agents_to_create_count * percentage)
                        profession_counts.append((profession, count))
                        total_assigned += count
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –∞–≥–µ–Ω—Ç–æ–≤ –∫ —Å–∞–º–æ–π –ø–æ–ø—É–ª—è—Ä–Ω–æ–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ (Teacher)
                    if total_assigned < agents_to_create_count:
                        remaining = agents_to_create_count - total_assigned
                        profession_counts[0] = ("Teacher", profession_counts[0][1] + remaining)
                    
                    agents_to_create = []
                    for profession, count in profession_counts:
                        for _ in range(count):
                            agent = Person.create_random_agent(
                                profession,
                                self.simulation_id,
                                ranges_map=self.profession_attr_ranges,
                            )
                            agents_to_create.append(agent)
                        
                    # –°–æ–∑–¥–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –∞–≥–µ–Ω—Ç–æ–≤
                    if agents_to_create:
                        await self.db_repo.bulk_create_persons(agents_to_create)
                    
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∏ –Ω–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤
                    self.agents = existing_agents + agents_to_create
                    
                    logger.info(json.dumps({
                        "event": "agents_created_according_tz",
                        "simulation_id": str(self.simulation_id),
                        "existing_count": existing_count,
                        "created_count": len(agents_to_create),
                        "total_count": len(self.agents),
                        "requested_count": num_agents,
                        "profession_distribution": {prof: count for prof, count in profession_counts},
                    }, default=str))
        
        # üÜï Ensure we have a row in simulation_participants for every agent
        for agent in self.agents:
            try:
                await self.db_repo.create_simulation_participant(self.simulation_id, agent.id)
            except Exception:
                # Ignore if the participant record already exists (e.g., rerun)
                pass
        
        # –ó–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∞—á–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã (–µ—Å–ª–∏ –µ—Å—Ç—å)
        existing_trends = await self.db_repo.get_active_trends(self.simulation_id)
        for trend in existing_trends:
            self.active_trends[str(trend.trend_id)] = trend
        
        # –ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è
        self._schedule_system_events()
        
        logger.info(json.dumps({
            "event": "simulation_initialized",
            "simulation_id": str(self.simulation_id),
            "agents_total": len(self.agents),
            "affinity_topics": len(self.affinity_map),
            "system_events_scheduled": len(self.event_queue)
        }, default=str))
        
    def _schedule_system_events(self) -> None:
        """–ü–ª–∞–Ω–∏—Ä—É–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è."""
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –°–æ–∑–¥–∞–µ–º –±–æ–ª—å—à–µ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π –¥–ª—è –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–π —Å–∏–º—É–ª—è—Ü–∏–∏
        
        # –ü–µ—Ä–≤–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —ç–Ω–µ—Ä–≥–∏–∏ —á–µ—Ä–µ–∑ 60 –º–∏–Ω—É—Ç, —á—Ç–æ–±—ã —Ä–∞–±–æ—Ç–∞—Ç—å –∏ –≤ –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–∏–º—É–ª—è—Ü–∏—è—Ö
        first_recovery_ts = 60.0
        energy_event = EnergyRecoveryEvent(first_recovery_ts)
        self.add_event(energy_event, EventPriority.SYSTEM, first_recovery_ts)
        
        # –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π —Å–±—Ä–æ—Å —á–µ—Ä–µ–∑ 24 —á–∞—Å–∞ (1440 –º–∏–Ω—É—Ç)
        daily_reset = DailyResetEvent(1440.0)
        self.add_event(daily_reset, EventPriority.SYSTEM, 1440.0)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–Ω–µ–≤–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —á–µ—Ä–µ–∑ 23 —á–∞—Å–∞ (1380 –º–∏–Ω—É—Ç)
        daily_save = SaveDailyTrendEvent(1380.0)
        self.add_event(daily_save, EventPriority.SYSTEM, 1380.0)
        
        # –î–û–ë–ê–í–õ–Ø–ï–ú: –ë–æ–ª–µ–µ —á–∞—Å—Ç—ã–µ —Å–æ–±—ã—Ç–∏—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è —ç–Ω–µ—Ä–≥–∏–∏
        for hour in range(1, 25, 3):  # –ö–∞–∂–¥—ã–µ 3 —á–∞—Å–∞
            if hour * 60.0 <= 1440.0:  # –í –ø—Ä–µ–¥–µ–ª–∞—Ö –¥–Ω—è
                energy_event = EnergyRecoveryEvent(hour * 60.0)
                self.add_event(energy_event, EventPriority.SYSTEM, hour * 60.0)
        
    async def run_simulation(self, duration_days: float = 1.0) -> None:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Å–∏–º—É–ª—è—Ü–∏–∏.
        
        Args:
            duration_days: –ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–∏–º—É–ª—è—Ü–∏–∏ –≤ –¥–Ω—è—Ö
        """
        if not self.simulation_id:
            raise RuntimeError("Simulation not initialized. Call initialize() first.")
            
        self._running = True
        end_time = duration_days * 1440.0  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –¥–Ω–∏ –≤ –º–∏–Ω—É—Ç—ã
        self._simulation_start_real = time.time()
        
        logger.info(json.dumps({
            "event": "simulation_started",
            "simulation_id": str(self.simulation_id),
            "duration_days": duration_days,
            "end_time": end_time,
            "agents_count": len(self.agents),
            "realtime_mode": settings.ENABLE_REALTIME,
            "speed_factor": settings.SIM_SPEED_FACTOR
        }, default=str))
        
        events_processed = 0
        agent_actions_scheduled = 0
        
        # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ—á–µ—Ä–µ–¥–∏
        # –í—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—á–µ—Ä–µ–¥–∏ —Å–æ–±—ã—Ç–∏–π –∏–∑-–∑–∞ –ø—Ä–æ–±–ª–µ–º —Å UUID
        # self._log_event_queue_status()
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü–ª–∞–Ω–∏—Ä—É–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –æ—á–µ—Ä–µ–¥–∏
        initial_scheduled = await self._schedule_seed_actions()
        agent_actions_scheduled += initial_scheduled
        
        logger.info(json.dumps({
            "event": "initial_actions_scheduled", 
            "scheduled_count": initial_scheduled,
            "queue_size": len(self.event_queue)
        }, default=str))
        
        try:
            while self._running and self.current_time < end_time:
                # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–ª–µ–¥—É—é—â–µ–µ —Å–æ–±—ã—Ç–∏–µ –∏–∑ –æ—á–µ—Ä–µ–¥–∏
                if self.event_queue:
                    priority_event = heapq.heappop(self.event_queue)
                    
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å sim_time –≤ real_time –¥–ª—è realtime —Ä–µ–∂–∏–º–∞
                    if priority_event.event.timestamp_real is None:
                        priority_event.event.timestamp_real = (
                            self._simulation_start_real + 
                            priority_event.timestamp * 60.0 / settings.SIM_SPEED_FACTOR
                        )
                    
                    # –û–∂–∏–¥–∞–Ω–∏–µ –¥–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–±—ã—Ç–∏—è –≤ realtime —Ä–µ–∂–∏–º–µ
                    if settings.ENABLE_REALTIME:
                        await self.clock.sleep_until(priority_event.timestamp)
                    
                    self.current_time = priority_event.timestamp
                    
                    # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–æ–±—ã—Ç–∏–µ
                    await self._process_event(priority_event.event)
                    events_processed += 1
                    
                    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å batch commit
                    if self._should_commit_batch():
                        await self._batch_commit_states()
                
                # –ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —Å–æ–±—ã—Ç–∏—è
                if events_processed % 50 == 0:  # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∫–∞–∂–¥—ã–µ 50 —Å–æ–±—ã—Ç–∏–π –≤–º–µ—Å—Ç–æ 10
                    scheduled = await self._schedule_agent_actions()
                    agent_actions_scheduled += scheduled
                    # –õ–æ–≥–∏—Ä—É–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ—á–µ—Ä–µ–¥–∏ –∫–∞–∂–¥—ã–µ 50 —Å–æ–±—ã—Ç–∏–π
                    # self._log_event_queue_status()
                else:
                    # –ï—Å–ª–∏ –æ—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞, –ø—Ä–æ–¥–≤–∏–≥–∞–µ–º –≤—Ä–µ–º—è –∏ –ø–ª–∞–Ω–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏—è
                    if not self.event_queue:
                        self.current_time += 5.0  # –ü—Ä–æ–¥–≤–∏–≥–∞–µ–º –Ω–∞ 5 –º–∏–Ω—É—Ç —Å–∏–º—É–ª—è—Ü–∏–∏
                        scheduled = await self._schedule_agent_actions()
                        agent_actions_scheduled += scheduled
                
                # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –¥–ª—è cooperative multitasking
                await asyncio.sleep(0.1 if settings.ENABLE_REALTIME else 0.001)
                
        except Exception as e:
            logger.error(json.dumps({
                "event": "simulation_error",
                "error": str(e),
                "current_time": self.current_time,
                "events_processed": events_processed
            }, default=str))
            raise
        finally:
            # –§–∏–Ω–∞–ª—å–Ω—ã–π batch commit
            await self._batch_commit_states()
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å —Å–∏–º—É–ª—è—Ü–∏–∏ –Ω–∞ COMPLETED —Å end_time
            await self.db_repo.update_simulation_status(
                self.simulation_id, 
                "COMPLETED",
                datetime.utcnow()
            )
            
            logger.info(json.dumps({
                "event": "simulation_completed",
                "simulation_id": str(self.simulation_id),
                "duration_minutes": self.current_time,
                "events_processed": events_processed,
                "agent_actions_scheduled": agent_actions_scheduled,
                "final_agents": len(self.agents),
                "final_trends": len(self.active_trends)
            }, default=str))
        
    async def _process_event(self, event: BaseEvent) -> None:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–Ω–æ —Å–æ–±—ã—Ç–∏–µ –∏–∑ –æ—á–µ—Ä–µ–¥–∏.
        
        Args:
            event: –°–æ–±—ã—Ç–∏–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        start_time = datetime.utcnow()
        
        try:
            # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–æ–±—ã—Ç–∏–µ
            event.process(self)
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –û–ø—Ä–µ–¥–µ–ª—è–µ–º agent_id –∏ trend_id –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ —Å–æ–±—ã—Ç–∏—è
            agent_id = None
            trend_id = None
            
            # –°–æ–±—ã—Ç–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –∏–º–µ—é—Ç agent_id
            if hasattr(event, 'agent_id'):
                agent_id = event.agent_id
                
            # –°–æ–±—ã—Ç–∏—è —Ç—Ä–µ–Ω–¥–æ–≤ –∏–º–µ—é—Ç trend_id  
            if hasattr(event, 'trend_id'):
                trend_id = event.trend_id
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ç—Ä–µ–Ω–¥ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–∞—Ö
                if trend_id and str(trend_id) not in self.active_trends:
                    logger.warning(json.dumps({
                        "event": "trend_not_found_for_event",
                        "trend_id": str(trend_id),
                        "event_type": event.__class__.__name__,
                        "timestamp": event.timestamp
                    }, default=str))
                    trend_id = None  # –ù–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ç—Ä–µ–Ω–¥
                
            # –°–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è –ù–ï –∏–º–µ—é—Ç agent_id –∏–ª–∏ trend_id
            # (EnergyRecoveryEvent, DailyResetEvent, SaveDailyTrendEvent)
            
            # –ó–∞–ø–∏—Å–∞—Ç—å —Å–æ–±—ã—Ç–∏–µ –≤ –ë–î –í–°–ï–ì–î–ê –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            from ..db.models import Event as DBEvent
            db_event = DBEvent(
                simulation_id=self.simulation_id,
                event_type=event.__class__.__name__,
                priority=event.priority,
                timestamp=event.timestamp,
                agent_id=agent_id,  # NULL –¥–ª—è —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π
                trend_id=trend_id,  # NULL –µ—Å–ª–∏ –Ω–µ —Å–≤—è–∑–∞–Ω–æ —Å —Ç—Ä–µ–Ω–¥–æ–º
                event_data={
                    "topic": getattr(event, 'topic', None),
                    "law_type": getattr(event, 'law_type', None),
                    "weather_type": getattr(event, 'weather_type', None),
                    "recovered_agents": getattr(event, 'recovered_agent_ids', None),
                    "event_id": str(event.event_id),
                    "sim_time": event.timestamp,
                    "real_time": event.timestamp_real
                },
                processed_at=datetime.utcnow()
            )
            
            processing_time = (datetime.utcnow() - start_time).total_seconds() * 1000
            db_event.processing_duration_ms = processing_time
            
            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–±—ã—Ç–∏–µ –≤ –ë–î
            await self.db_repo.create_event(db_event)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π commit –ø–æ—Å–ª–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π
            if getattr(self, '_force_commit_after_this_event', False):
                await self._batch_commit_states()
                self._force_commit_after_this_event = False
                
        except Exception as e:
            logger.error(json.dumps({
                "event": "event_processing_error",
                "event_type": event.__class__.__name__,
                "event_id": str(event.event_id),
                "error": str(e),
                "timestamp": event.timestamp
            }, default=str))
            raise
        
    async def _schedule_seed_actions(self) -> int:
        """
        –°–æ–∑–¥–∞–µ—Ç –ø–µ—Ä–≤–∏—á–Ω—ã–µ seed —Å–æ–±—ã—Ç–∏—è –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤, –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –¥–ª—è PublishPost.
        
        –°–µ–ª–µ–∫—Ç–∏–≤–Ω–æ –≤—ã–±–∏—Ä–∞–µ—Ç –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ö –∞—Ç—Ä–∏–±—É—Ç–æ–≤:
        - –î–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è —ç–Ω–µ—Ä–≥–∏—è (>= 1.5)  
        - –î–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π –±—é–¥–∂–µ—Ç (>= 2)
        - –í—ã—Å–æ–∫–∞—è —Å–æ—Ü–∏–∞–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (social_status >= 2.0)
        - –°–∫–ª–æ–Ω–Ω–æ—Å—Ç—å –∫ –ø—É–±–ª–∏–∫–∞—Ü–∏—è–º (trend_receptivity >= 2.0)
        """
        scheduled_count = 0
        context = SimulationContext(
            current_time=self.current_time,
            active_trends=self.active_trends,
            affinity_map=self.affinity_map
        )
        
        # –°–µ–ª–µ–∫—Ç–∏–≤–Ω—ã–π –æ—Ç–±–æ—Ä –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è seed —Å–æ–±—ã—Ç–∏–π
        suitable_agents = []
        for agent in self.agents:
            if (agent.energy_level >= 0.5 and  # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: —Å–Ω–∏–∂–∞–µ–º —Å 1.5 –¥–æ 0.5
                agent.time_budget >= 1 and     # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: —Å–Ω–∏–∂–∞–µ–º —Å 2 –¥–æ 1
                agent.social_status >= 1.0 and # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: —Å–Ω–∏–∂–∞–µ–º —Å 2.0 –¥–æ 1.0
                agent.trend_receptivity >= 0.5): # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: —Å–Ω–∏–∂–∞–µ–º —Å 2.0 –¥–æ 0.5
                suitable_agents.append(agent)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ seed —Å–æ–±—ã—Ç–∏–π (10-20% –æ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∞–≥–µ–Ω—Ç–æ–≤)
        import random
        if not suitable_agents:
            logger.warning(json.dumps({
                "event": "no_suitable_agents_for_seed",
                "total_agents": len(self.agents),
                "timestamp": self.current_time
            }, default=str))
            return 0
            
        seed_count = max(1, min(len(suitable_agents), int(len(suitable_agents) * 0.15)))
        selected_agents = random.sample(suitable_agents, seed_count)
        
        logger.info(json.dumps({
            "event": "seed_selection",
            "total_agents": len(self.agents),
            "suitable_agents": len(suitable_agents),
            "selected_for_seed": seed_count,
            "timestamp": self.current_time
        }, default=str))
        
        # –°–æ–∑–¥–∞–µ–º seed —Å–æ–±—ã—Ç–∏—è —Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        time_slots = []
        if selected_agents:
            # –†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–æ–±—ã—Ç–∏—è –≤ –ø–µ—Ä–≤—ã–µ 60 –º–∏–Ω—É—Ç
            interval = 60.0 / len(selected_agents)
            for i in range(len(selected_agents)):
                base_time = i * interval
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à–æ–π —Å–ª—É—á–∞–π–Ω—ã–π —Ä–∞–∑–±—Ä–æ—Å ¬±5 –º–∏–Ω—É—Ç
                jitter = random.uniform(-5.0, 5.0)
                time_slots.append(max(1.0, base_time + jitter))
        
        for i, agent in enumerate(selected_agents):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π –ª–∏–º–∏—Ç –¥–µ–π—Å—Ç–≤–∏–π (43 –≤ –¥–µ–Ω—å)
            if not self._can_agent_act_today(agent.id):
                continue
                
            # –ê–≥–µ–Ω—Ç –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ä–µ—à–µ–Ω–∏–µ –æ —Ç–µ–º–µ
            topic = agent._select_best_topic(context)
            if topic:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥—Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Å–ª–æ—Ç
                delay = time_slots[i] if i < len(time_slots) else random.uniform(1.0, 60.0)
                
                action_event = PublishPostAction(
                    agent_id=agent.id,
                    topic=topic,
                    timestamp=self.current_time + delay
                )
                
                self.add_event(action_event, EventPriority.AGENT_ACTION, action_event.timestamp)
                self._track_agent_daily_action(agent.id)
                scheduled_count += 1
                
                logger.debug(json.dumps({
                    "event": "seed_action_scheduled",
                    "agent_id": str(agent.id),
                    "topic": topic,
                    "delay_minutes": delay,
                    "timestamp": action_event.timestamp
                }, default=str))
        
        return scheduled_count

    def _can_agent_act_today(self, agent_id: UUID) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –º–æ–∂–µ—Ç –ª–∏ –∞–≥–µ–Ω—Ç –µ—â–µ –¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å —Å–µ–≥–æ–¥–Ω—è (–ª–∏–º–∏—Ç 43 –¥–µ–π—Å—Ç–≤–∏—è)."""
        current_day = int(self.current_time // 1440)
        day_key = f"{agent_id}_{current_day}"
        
        if not hasattr(self, '_daily_action_counts'):
            self._daily_action_counts = {}
            
        current_count = self._daily_action_counts.get(day_key, 0)
        return current_count < 43

    def _track_agent_daily_action(self, agent_id: UUID) -> None:
        """–û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ–π—Å—Ç–≤–∏–π –∞–≥–µ–Ω—Ç–∞ –∑–∞ –¥–µ–Ω—å."""
        current_day = int(self.current_time // 1440)
        day_key = f"{agent_id}_{current_day}"
        
        if not hasattr(self, '_daily_action_counts'):
            self._daily_action_counts = {}
            
        self._daily_action_counts[day_key] = self._daily_action_counts.get(day_key, 0) + 1

    def _process_update_state_batch(self, update_state_batch: List[Dict]) -> None:
        """
        –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ updatestate –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –∞–≥–µ–Ω—Ç–æ–≤.
        
        –í–ê–ñ–ù–û: –ò–∑–º–µ–Ω–µ–Ω–∏—è –∑–∞–ø–∏—Å—ã–≤–∞—é—Ç—Å—è –≤ person_attribute_history, –∞ –Ω–µ —Å–æ–∑–¥–∞—é—Ç –Ω–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤.
        
        Args:
            update_state_batch: –°–ø–∏—Å–æ–∫ –ø–∞–∫–µ—Ç–æ–≤ –∏–∑–º–µ–Ω–µ–Ω–∏–π —Å–æ—Å—Ç–æ—è–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤
        """
        for update_state in update_state_batch:
            agent_id = update_state["agent_id"]
            agent = next((a for a in self.agents if str(a.id) == str(agent_id)), None)
            if not agent:
                continue
            for attr_name, delta in update_state["attribute_changes"].items():
                old_value = getattr(agent, attr_name, None)
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–µ
                if attr_name in ["energy_level", "financial_capability", "trend_receptivity", "social_status"]:
                    new_value = max(0.0, min(5.0, old_value + delta))
                elif attr_name == "time_budget":
                    new_value = max(0, min(5, int(old_value + delta)))
                else:
                    new_value = old_value + delta
                setattr(agent, attr_name, new_value)
                # –õ–æ–≥–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ç–æ–ª—å–∫–æ –¥–ª—è –∑–Ω–∞—á–∏–º—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
                if abs(delta) >= 0.01:
                    history_record = {
                        "type": "attribute_history",
                        "person_id": agent_id,
                        "simulation_id": self.simulation_id,
                        "attribute_name": attr_name,
                        "old_value": old_value,
                        "new_value": new_value,
                        "delta": delta,
                        "reason": update_state["reason"],
                        "source_trend_id": update_state.get("source_trend_id"),
                        "change_timestamp": update_state["timestamp"]
                    }
                    self.add_to_batch_update(history_record)
            person_update = {
                "type": "person_state",
                "id": agent_id,
                "reason": update_state["reason"],
                "source_trend_id": update_state.get("source_trend_id"),
                "timestamp": update_state["timestamp"]
            }
            for attr, delta in update_state["attribute_changes"].items():
                person_update[attr] = getattr(agent, attr, None)
            self.add_to_batch_update(person_update)
        logger.info(json.dumps({
            "event": "update_state_batch_processed",
            "batch_size": len(update_state_batch),
            "timestamp": self.current_time
        }, default=str))

    def _schedule_actions_batch(self, new_actions_batch: List[Dict]) -> int:
        """
        –ü–∞–∫–µ—Ç–Ω–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π –∞–≥–µ–Ω—Ç–æ–≤.
        
        Args:
            new_actions_batch: –°–ø–∏—Å–æ–∫ –Ω–æ–≤—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π
        """
        scheduled_count = 0
        
        for action_data in new_actions_batch:
            agent_id = action_data["agent_id"]
            action_type = action_data["action_type"]
            timestamp = action_data["timestamp"]
            
            if action_type == "PublishPostAction":
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ trigger_trend_id —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–∞—Ö
                trigger_trend_id = action_data.get("trigger_trend_id")
                if trigger_trend_id and str(trigger_trend_id) not in self.active_trends:
                    logger.warning(json.dumps({
                        "event": "trigger_trend_not_found",
                        "trigger_trend_id": str(trigger_trend_id),
                        "agent_id": str(agent_id),
                        "timestamp": timestamp
                    }, default=str))
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ trigger_trend_id
                    trigger_trend_id = None
                
                action_event = PublishPostAction(
                    agent_id=agent_id,
                    topic=action_data["topic"],
                    timestamp=timestamp,
                    trigger_trend_id=trigger_trend_id
                )
                
                self.add_event(action_event, EventPriority.AGENT_ACTION, timestamp)
                self._track_agent_daily_action(agent_id)
                scheduled_count += 1
                
                logger.debug(json.dumps({
                    "event": "batch_action_scheduled",
                    "agent_id": str(agent_id),
                    "action_type": action_type,
                    "topic": action_data["topic"],
                    "timestamp": timestamp,
                    "trigger_trend": str(action_data.get("trigger_trend_id", ""))
                }, default=str))
        
        return scheduled_count
        
    async def _schedule_agent_actions(self) -> int:
        """
        –ü–ª–∞–Ω–∏—Ä—É–µ—Ç –Ω–æ–≤—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –°–£–©–ï–°–¢–í–£–Æ–©–ò–• –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ v1.8 –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π.
        
        –í–ê–ñ–ù–û: –ù–ï —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ - —Ç–æ–ª—å–∫–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —É–∂–µ —Å–æ–∑–¥–∞–Ω–Ω—ã–º–∏.
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –¥–ª—è –ø–æ–ø–æ–ª–Ω–µ–Ω–∏—è –æ—á–µ—Ä–µ–¥–∏ —Å–æ–±—ã—Ç–∏–π.
        
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π
        """
        from capsim.simulation.actions.factory import ACTION_FACTORY
        import random
        
        scheduled_count = 0
        context = SimulationContext(
            current_time=self.current_time,
            active_trends=self.active_trends,
            affinity_map=self.affinity_map
        )
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫—É–ª–¥–∞—É–Ω—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if not hasattr(self, '_agent_action_cooldowns'):
            self._agent_action_cooldowns = {}
        
        # –†–∞–±–æ—Ç–∞–µ–º –¢–û–õ–¨–ö–û —Å —É–∂–µ —Å–æ–∑–¥–∞–Ω–Ω—ã–º–∏ –∞–≥–µ–Ω—Ç–∞–º–∏
        eligible_agents = []
        for agent in self.agents:
            if agent.energy_level <= 0 or agent.time_budget <= 0:
                continue
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π –ª–∏–º–∏—Ç –¥–µ–π—Å—Ç–≤–∏–π (—Å–Ω—è—Ç–æ –≤ v1.8 - –µ—Å—Ç—å –ª–∏–º–∏—Ç—ã –ø–æ —Ç–∏–ø–∞–º)
            # if not self._can_agent_act_today(agent.id):
            #     continue
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—É–ª–¥–∞—É–Ω –∞–≥–µ–Ω—Ç–∞ (—Å–Ω–∏–∂–µ–Ω–æ –¥–æ 15 –º–∏–Ω—É—Ç –≤ v1.8)
            last_action_time = self._agent_action_cooldowns.get(agent.id, 0)
            if self.current_time - last_action_time < 15.0:
                continue
                
            eligible_agents.append(agent)
        
        # v1.8: –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –¥–æ 20% –æ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤
        max_actions = max(1, min(len(eligible_agents), int(len(eligible_agents) * 0.2)))
        selected_agents = random.sample(eligible_agents, min(max_actions, len(eligible_agents)))
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π –≥–ª–∞–≤–Ω—ã–π —Ç—Ä–µ–Ω–¥ –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ —Ä–µ—à–µ–Ω–∏—è
        current_trend = None
        if self.active_trends:
            # –ë–µ—Ä–µ–º —Ç—Ä–µ–Ω–¥ —Å –Ω–∞–∏–≤—ã—Å—à–µ–π –≤–∏—Ä–∞–ª—å–Ω–æ—Å—Ç—å—é
            current_trend = max(self.active_trends.values(), key=lambda t: t.calculate_current_virality())
        
        for agent in selected_agents:
            # v1.8: –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π
            action_name = agent.decide_action_v18(current_trend, self.current_time)
            if not action_name:
                continue
                
            # –ü–æ–ª—É—á–∞–µ–º –≥–æ—Ç–æ–≤—ã–π –æ–±—ä–µ–∫—Ç –¥–µ–π—Å—Ç–≤–∏—è –∏–∑ —Ñ–∞–±—Ä–∏–∫–∏ (–∏–ª–∏ –∫–ª–∞—Å—Å –¥–ª—è BC)
            action_obj = ACTION_FACTORY.get(action_name)
            if not action_obj:
                logger.warning(json.dumps({
                    "event": "unknown_action_type",
                    "action_name": action_name,
                    "agent_id": str(agent.id)
                }))
                continue
                
            # –ï—Å–ª–∏ –≤ –º–∞–ø–µ –ª–µ–∂–∏—Ç –∫–ª–∞—Å—Å (legacy), –∏–Ω—Å—Ç–∞–Ω—Ü–∏—Ä—É–µ–º, –∏–Ω–∞—á–µ –±–µ—Ä—ë–º –∫–∞–∫ –µ—Å—Ç—å
            if isinstance(action_obj, type):
                action = action_obj()
            else:
                action = action_obj

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            if not action.can_execute(agent, self.current_time):
                continue
                
            # v1.8: –í—ã–ø–æ–ª–Ω—è–µ–º –¥–µ–π—Å—Ç–≤–∏–µ –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ (–Ω–µ –æ—Ç–∫–ª–∞–¥—ã–≤–∞–µ–º)
            try:
                action.execute(agent, self)
                self._agent_action_cooldowns[agent.id] = self.current_time
                scheduled_count += 1
                
                logger.debug(json.dumps({
                    "event": "v18_action_executed",
                    "agent_id": str(agent.id),
                    "action_name": action_name,
                    "profession": agent.profession,
                    "timestamp": self.current_time,
                    "energy_after": agent.energy_level,
                    "purchases_today": getattr(agent, 'purchases_today', 0)
                }, default=str))
                
            except Exception as e:
                logger.error(json.dumps({
                    "event": "action_execution_error",
                    "agent_id": str(agent.id),
                    "action_name": action_name,
                    "error": str(e)
                }, default=str))
        
        if scheduled_count > 0:
            logger.info(json.dumps({
                "event": "v18_agent_actions_scheduled",
                "eligible_agents": len(eligible_agents),
                "selected_agents": len(selected_agents),
                "scheduled_count": scheduled_count,
                "timestamp": self.current_time,
                "current_trend": str(current_trend.trend_id) if current_trend else None
            }, default=str))
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ª—ë–≥–∫–∏–π –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ Wellness-–¥–µ–π—Å—Ç–≤–∏–π (Purchase/SelfDev)
        scheduled_count += self._schedule_random_wellness()
        
        return scheduled_count

    def _schedule_random_wellness(self) -> int:
        """–°–ª—É—á–∞–π–Ω–æ –ø–ª–∞–Ω–∏—Ä—É–µ—Ç Purchase –∏–ª–∏ SelfDev, —á—Ç–æ–±—ã –æ–±–µ—Å–ø–µ—á–∏—Ç—å ‚â•1 –¥–µ–π—Å—Ç–≤–∏–µ/–∞–≥–µ–Ω—Ç/—Å–∏–º-—á–∞—Å."""
        import random
        from capsim.simulation.actions.factory import ACTION_FACTORY

        actions_planned = 0

        if not self.agents:
            return 0

        # –ü—Ä–∏–±–ª–∏–∑–∏–º—Å—è –∫ 10 % –∞–≥–µ–Ω—Ç–æ–≤ –∫–∞–∂–¥—ã–π —Å–∏–º-—á–∞—Å (60 –º–∏–Ω—É—Ç).
        # –ú–µ—Ç–æ–¥ –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è —Ä–∞–∑ –≤ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç, –ø–æ—ç—Ç–æ–º—É –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º.
        prob = 1.0 / 60  # ‚âà0.0167 per minute (~1 –¥–µ–π—Å—Ç–≤–∏–µ/–∞–≥–µ–Ω—Ç/—á–∞—Å)

        for agent in self.agents:
            if random.random() > prob:
                continue

            # –í—ã–±–æ—Ä –¥–µ–π—Å—Ç–≤–∏—è: –µ—Å–ª–∏ energy<3 ‚Üí SelfDev, –∏–Ω–∞—á–µ Purchase L1-L3.
            if agent.energy_level < 3.0:
                action = ACTION_FACTORY["SelfDev"]
            else:
                level = random.choice(["L1", "L2", "L3"])
                action = ACTION_FACTORY[f"Purchase_{level}"]

            if action.can_execute(agent, self.current_time):
                try:
                    action.execute(agent, self)
                    actions_planned += 1
                except Exception:
                    continue

        return actions_planned

    def add_event(self, event: BaseEvent, priority: int, timestamp: float) -> None:
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–±—ã—Ç–∏–µ –≤ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—É—é –æ—á–µ—Ä–µ–¥—å.
        
        Args:
            event: –°–æ–±—ã—Ç–∏–µ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
            priority: –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç —Å–æ–±—ã—Ç–∏—è (1-5)
            timestamp: –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        """
        priority_event = PriorityEvent(priority, timestamp, event)
        heapq.heappush(self.event_queue, priority_event)
        
    def add_to_batch_update(self, update: Dict[str, Any]) -> None:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤ batch –æ—á–µ—Ä–µ–¥—å."""
        self._batch_updates.append(update)
        
    def _should_commit_batch(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω—É–∂–Ω–æ –ª–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç—å batch commit."""
        # Commit –ø–æ —Ä–∞–∑–º–µ—Ä—É
        if len(self._batch_updates) >= self.batch_size:
            return True
            
        # Commit –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É –∫ realtime —Ä–µ–∂–∏–º—É)
        if settings.ENABLE_REALTIME:
            # –í realtime —Ä–µ–∂–∏–º–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º wall-clock –≤—Ä–µ–º—è
            time_since_last = time.time() - self._last_commit_time
            timeout_seconds = settings.get_batch_timeout_seconds()
            if time_since_last >= timeout_seconds:
                return True
        else:
            # –í fast —Ä–µ–∂–∏–º–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º sim –≤—Ä–µ–º—è
            if self.current_time - self._last_batch_commit >= self.batch_timeout_minutes:
                return True
            
        return False
        
    async def _batch_commit_states(self) -> None:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç batch commit –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã—Ö –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π —Å–æ—Å—Ç–æ—è–Ω–∏—è.
        
        –í–ê–ñ–ù–û: –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ person_attribute_history –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤.
        
        –í–∫–ª—é—á–∞–µ—Ç —Ä–µ—Ç—Ä–∞–∏ —Å —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–º backoff –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö.
        """
        if not self._batch_updates:
            return
            
        updates_count = len(self._batch_updates)
        retry_attempts = settings.BATCH_RETRY_ATTEMPTS
        backoffs = settings.get_batch_retry_backoffs()
        
        for attempt in range(retry_attempts):
            try:
                start_time = time.time()
                
                # –†–∞–∑–¥–µ–ª–∏—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ —Ç–∏–ø–∞–º
                person_updates = [u for u in self._batch_updates if u.get("type") == "person_state"]
                history_records = [u for u in self._batch_updates if u.get("type") == "attribute_history"]
                trend_updates = [u for u in self._batch_updates if u.get("type") == "trend_interaction"]
                trend_creations = [u for u in self._batch_updates if u.get("type") == "trend_creation"]
                
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∑–∞–ø–∏—Å–∏ –∏—Å—Ç–æ—Ä–∏–∏ –∞—Ç—Ä–∏–±—É—Ç–æ–≤
                if history_records:
                    from ..db.models import PersonAttributeHistory
                    for history_data in history_records:
                        # –°–æ–∑–¥–∞–µ–º DB –º–æ–¥–µ–ª—å –∏—Å—Ç–æ—Ä–∏–∏ –∞—Ç—Ä–∏–±—É—Ç–æ–≤
                        db_history = PersonAttributeHistory(
                            person_id=history_data["person_id"],
                            simulation_id=history_data["simulation_id"],
                            attribute_name=history_data["attribute_name"],
                            old_value=history_data["old_value"],
                            new_value=history_data["new_value"],
                            delta=history_data["delta"],
                            reason=history_data["reason"],
                            source_trend_id=history_data.get("source_trend_id"),
                            change_timestamp=history_data["change_timestamp"]
                        )
                        await self.db_repo.create_person_attribute_history(db_history)
                
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –û–±–Ω–æ–≤–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤
                if person_updates:
                    # –†–∞–∑–¥–µ–ª—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–∞ Person –∏ SimulationParticipant
                    person_updates_clean = []
                    participant_updates = []
                    
                    for update in person_updates:
                        # –û–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã Person
                        person_update = {
                            'id': update['id'],
                        }
                        # –û–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã SimulationParticipant
                        participant_update = {
                            'simulation_id': self.simulation_id,
                            'person_id': update['id'],
                        }
                        
                        # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–ª—è –ø–æ —Ç–∞–±–ª–∏—Ü–∞–º
                        for key, value in update.items():
                            if key not in ['type', 'id', 'reason', 'source_trend_id', 'timestamp']:
                                if key in ['last_post_ts', 'last_selfdev_ts', 'last_purchase_ts', 'purchases_today']:
                                    # –≠—Ç–∏ –ø–æ–ª—è –∏–¥—É—Ç –≤ SimulationParticipant
                                    participant_update[key] = value
                                else:
                                    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è –∏–¥—É—Ç –≤ Person
                                    person_update[key] = value
                        
                        if len(person_update) > 1:  # –ï—Å—Ç—å –ø–æ–ª—è –¥–ª—è Person
                            person_updates_clean.append(person_update)
                        if len(participant_update) > 2:  # –ï—Å—Ç—å –ø–æ–ª—è –¥–ª—è SimulationParticipant
                            participant_updates.append(participant_update)
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º Person
                    if person_updates_clean:
                        await self.db_repo.bulk_update_persons(person_updates_clean)
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º SimulationParticipant
                    if participant_updates:
                        await self.db_repo.bulk_update_simulation_participants(participant_updates)
                
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–µ —Ç—Ä–µ–Ω–¥—ã –≤ –ë–î
                if trend_creations:
                    from ..db.models import Trend as DBTrend
                    for trend_data in trend_creations:
                        # –°–æ–∑–¥–∞–µ–º DB –º–æ–¥–µ–ª—å –∏–∑ –¥–∞–Ω–Ω—ã—Ö
                        db_trend = DBTrend(
                            trend_id=trend_data["trend_id"],
                            simulation_id=trend_data["simulation_id"],
                            topic=trend_data["topic"],
                            originator_id=trend_data["originator_id"],
                            base_virality_score=trend_data["base_virality_score"],
                            coverage_level=trend_data["coverage_level"],
                            sentiment=trend_data["sentiment"],
                        )
                        await self.db_repo.create_trend(db_trend)
                
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å —Ç—Ä–µ–Ω–¥–∞–º–∏
                if trend_updates:
                    for update in trend_updates:
                        await self.db_repo.increment_trend_interactions(update["trend_id"])
                
                commit_time = (time.time() - start_time) * 1000
                
                # –û—á–∏—Å—Ç–∏—Ç—å batch
                self._batch_updates.clear()
                self._last_batch_commit = self.current_time
                
                logger.info(json.dumps({
                    "event": "batch_commit_success",
                    "simulation_id": str(self.simulation_id),
                    "updates_count": updates_count,
                    "history_records": len(history_records),
                    "person_updates": len(person_updates),
                    "trend_updates": len(trend_updates),
                    "trend_creations": len(trend_creations),
                    "commit_time_ms": commit_time,
                    "attempt": attempt + 1
                }, default=str))
                return
                
            except Exception as e:
                if attempt < retry_attempts - 1:
                    backoff_time = backoffs[min(attempt, len(backoffs) - 1)]
                    logger.warning(json.dumps({
                        "event": "batch_commit_retry",
                        "error": str(e),
                        "attempt": attempt + 1,
                        "backoff_seconds": backoff_time
                    }, default=str))
                    await asyncio.sleep(backoff_time)
                else:
                    logger.error(json.dumps({
                        "event": "batch_commit_failed",
                        "error": str(e),
                        "updates_lost": updates_count,
                        "final_attempt": attempt + 1
                    }, default=str))
                    # –û—á–∏—Å—Ç–∏—Ç—å batch –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è
                    self._batch_updates.clear()
        
    async def archive_inactive_trends(self) -> None:
        """
        –ê—Ä—Ö–∏–≤–∏—Ä—É–µ—Ç –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã (–±–µ–∑ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π 3+ –¥–Ω—è).
        """
        current_datetime = datetime.utcnow() - timedelta(minutes=self.current_time)
        archived_count = 0
        
        trends_to_remove = []
        for trend_id, trend in self.active_trends.items():
            if not trend.is_active(current_datetime, self.trend_archive_threshold_days):
                trends_to_remove.append(trend_id)
                archived_count += 1
                
        # –£–¥–∞–ª–∏—Ç—å –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã
        for trend_id in trends_to_remove:
            del self.active_trends[trend_id]
            
        if archived_count > 0:
            logger.info(json.dumps({
                "event": "trends_archived",
                "archived_count": archived_count,
                "active_remaining": len(self.active_trends),
                "timestamp": self.current_time
            }, default=str))
        
    def get_simulation_stats(self) -> Dict:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–∏–º—É–ª—è—Ü–∏–∏.
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ —Å–∏–º—É–ª—è—Ü–∏–∏
        """
        active_agents = sum(1 for agent in self.agents if agent.energy_level > 0)
        
        return {
            "simulation_id": str(self.simulation_id) if self.simulation_id else None,
            "current_time": self.current_time,
            "active_agents": active_agents,
            "total_agents": len(self.agents),
            "active_trends": len(self.active_trends),
            "queue_size": len(self.event_queue),
            "pending_batches": len(self._batch_updates),
            "running": self._running
        }
        
    async def shutdown(self) -> None:
        """Graceful shutdown —Å–∏–º—É–ª—è—Ü–∏–∏."""
        self._running = False
        
        # –§–∏–Ω–∞–ª—å–Ω—ã–π commit
        await self._batch_commit_states()
        
        logger.info(json.dumps({
            "event": "simulation_shutdown",
            "final_time": self.current_time,
            "final_stats": self.get_simulation_stats()
        }, default=str))
        
    def clear_event_queue(self) -> int:
        """
        –û—á–∏—â–∞–µ—Ç –æ—á–µ—Ä–µ–¥—å —Å–æ–±—ã—Ç–∏–π –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π.
        
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—á–∏—â–µ–Ω–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π
        """
        cleared_count = len(self.event_queue)
        self.event_queue.clear()
        
        logger.info(json.dumps({
            "event": "event_queue_cleared",
            "simulation_id": str(self.simulation_id) if self.simulation_id else None,
            "cleared_events": cleared_count,
            "current_time": self.current_time
        }, default=str))
        
        return cleared_count
        
    async def stop_simulation(self, method: str = "graceful") -> None:
        """
        –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å–∏–º—É–ª—è—Ü–∏—é —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º –º–µ—Ç–æ–¥–æ–º.
        
        Args:
            method: "graceful" –∏–ª–∏ "force"
        """
        stop_start_time = time.time()
        
        logger.info(json.dumps({
            "event": "simulation_stop_initiated",
            "simulation_id": str(self.simulation_id) if self.simulation_id else None,
            "method": method,
            "current_time": self.current_time,
            "queue_size": len(self.event_queue),
            "pending_batches": len(self._batch_updates)
        }, default=str))
        
        if method == "graceful":
            # Graceful stop: –∑–∞–≤–µ—Ä—à–∏—Ç—å —Ç–µ–∫—É—â–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
            self._running = False
            
            # –§–∏–Ω–∞–ª—å–Ω—ã–π batch commit
            await self._batch_commit_states()
            
            # –û—á–∏—Å—Ç–∏—Ç—å –æ—á–µ—Ä–µ–¥—å —Å–æ–±—ã—Ç–∏–π
            cleared_events = self.clear_event_queue()
            
            # –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å —Å–∏–º—É–ª—è—Ü–∏–∏ –≤ –ë–î
            if self.simulation_id:
                await self.db_repo.update_simulation_status(
                    self.simulation_id, 
                    "STOPPED",
                    datetime.utcnow()
                )
                
        elif method == "force":
            # Force stop: –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞
            self._running = False
            
            # –û—á–∏—Å—Ç–∏—Ç—å –æ—á–µ—Ä–µ–¥—å –±–µ–∑ batch commit
            cleared_events = self.clear_event_queue()
            
            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–≤–µ—Ä—à–∏—Ç—å –≤ –ë–î
            if self.simulation_id:
                await self.db_repo.force_complete_simulation(self.simulation_id)
                
        stop_duration = time.time() - stop_start_time
        
        logger.info(json.dumps({
            "event": "simulation_stopped",
            "simulation_id": str(self.simulation_id) if self.simulation_id else None,
            "method": method,
            "stop_duration_seconds": stop_duration,
            "events_cleared": cleared_events,
            "final_time": self.current_time,
            "data_preserved": method == "graceful"
        }, default=str)) 

    async def _cleanup_stale_simulations(self) -> None:
        """
        –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–≤–µ—Ä—à–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ —Å–∏–º—É–ª—è—Ü–∏–∏ —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º RUNNING.
        –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –≤–∏—Å—è—â–∏–µ –∑–∞–ø–∏—Å–∏ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.
        """
        try:
            # –ù–∞–π—Ç–∏ –≤—Å–µ —Å–∏–º—É–ª—è—Ü–∏–∏ —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º RUNNING
            stale_simulations = await self.db_repo.get_simulations_by_status("RUNNING")
            
            for simulation in stale_simulations:
                logger.warning(json.dumps({
                    "event": "cleaning_stale_simulation",
                    "simulation_id": str(simulation.run_id),
                    "start_time": str(simulation.start_time),
                    "status": simulation.status
                }, default=str))
                
                # –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –Ω–∞ FAILED —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–º
                await self.db_repo.update_simulation_status(
                    simulation.run_id,
                    "FAILED",
                    datetime.utcnow(),
                    reason="Stale simulation cleanup"
                )
                
        except Exception as e:
            logger.error(json.dumps({
                "event": "cleanup_stale_simulations_error",
                "error": str(e)
            }, default=str)) 